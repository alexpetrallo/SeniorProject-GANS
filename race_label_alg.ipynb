{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1_0_1_20170112211228948.jpg\n",
       "1         4_1_1_20170112210412852.jpg\n",
       "2         4_1_1_20170112210910341.jpg\n",
       "3         5_0_1_20170112191417872.jpg\n",
       "4         5_1_1_20170112210544957.jpg\n",
       "                     ...             \n",
       "10714    90_1_1_20170117194843274.jpg\n",
       "10715    91_0_1_20170117194736477.jpg\n",
       "10716    96_1_1_20170117183936388.jpg\n",
       "10717    99_0_0_20170117195137161.jpg\n",
       "10718    99_1_2_20170117195405372.jpg\n",
       "Name: 0, Length: 10719, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Race labeling\n",
    "\n",
    "# General libraries\n",
    "import pandas as pd  #For working with dataframes\n",
    "import numpy as np   #For working with image arrays\n",
    "import cv2          #For transforming image\n",
    "import matplotlib.pyplot as plt  #For representation\n",
    "\n",
    "#For model building \n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models, utils\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F\n",
    "from skimage import io, transform\n",
    "from torch.optim import lr_scheduler\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "#Converting .txt file to . csv file using pandas\n",
    "#Loading landmarks_list_part2.csv\n",
    "landmarks_frame = pd.read_csv('./race_data/landmark_list_part2.csv', sep = '\\s+', header = None)\n",
    "\n",
    "#Labeling / Parse\n",
    "n = 10 #number of people \n",
    "i = 0\n",
    "\n",
    "#converting to series\n",
    "labels = landmarks_frame.iloc[0:n, 0].str.split('_')\n",
    "\n",
    "landmarks_frame = landmarks_frame.astype({0 : str })\n",
    "landmarks_frame[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and normalizing UTKFace images \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# The Generator - consists od transposed convolution layers \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.\n",
    "\n",
    "        \n",
    "# defining hyperparameters\n",
    "n_epochs = 3 # how many times we'// loop over the complete training dataset\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5 # optimizer will be using learning rate and momentum \n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1 # repeatable experiments need to set random seeds  \n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
